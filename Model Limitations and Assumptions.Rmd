---
output:
  pdf_document: default
  html_document: default
---
ï»¿---
title: "HARVARD EXTENSION SCHOOL"
subtitle: "Titanic Survival Classification: Group Project Report"
author:
- Student One (HUID XXXXXXXX)
- Student Two (HUID XXXXXXXX)
- Student Three (HUID XXXXXXXX)
tags: [logistic regression, decision tree, classification]
abstract: |
  This report builds a champion/benchmark modeling solution to predict
  passenger survival on the RMS Titanic. We demonstrate a complete model
  lifecycle: exploratory analysis, data preparation, model training,
  challenger comparison, performance evaluation, limitations, and
  monitoring recommendations. All R code and interpretations are included
  so the analysis is reproducible and transparent.
date: "`r format(Sys.time(), '%d %B %Y')`"
geometry: margin=1.3cm
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(broom)
library(rpart)
library(rpart.plot)

Titanic.Raw <- read_csv("Titanic_Survival_Data.csv", show_col_types = FALSE)
```

## Executive Summary

We predict Titanic passenger survival using demographic and ticketing
information. A cleaned dataset of 1,310 records is split 70/30
train/test (set.seed = 1023). The champion model is a parsimonious
logistic regression using class, sex, age, family size, fare, and port
of embarkation. A decision tree is built as the challenger. Both models
perform substantially better than chance; the logistic model yields
balanced accuracy and interpretable odds ratios, while the tree offers
transparent rules but slightly lower hold-out accuracy. Monitoring
should track drift in class mix, gender mix, and fare distributions, and
trigger review when accuracy drops below 80% or when input distributions
shift beyond training percentiles. Key limitations include missing
values (age, fare, cabin), potential historical bias, and simplified
imputations.

**Interpretation:** Senior stakeholders can rely on the logistic model
for consistent discrimination and clear business storytelling (e.g.,
women and 1st-class passengers had markedly higher survival odds), while
the tree provides an audit-friendly benchmark.

## I. Introduction (5 points)

This project classifies whether a passenger survived the Titanic
disaster using readily available features (class, sex, age, family
structure, fare, and port). We evaluate two supervised classification
methods: logistic regression (champion) and decision tree (challenger).
The train sample contains 70% of the data (n ~ 917), the test sample the
remaining 30% (n ~ 393). Success is defined by accurate and explainable
survival predictions that generalize to the hold-out test set.


## II. Description of the Data and Quality (15 points)

The dataset contains 1,310 observations and 14 original variables. Key
predictors are mixed categorical (class, sex, embarked) and numeric
(age, fare, family counts). Several variables contain substantial
missingness (age, cabin, boat, body).

```{r data_overview}
glimpse(Titanic.Raw)

# Table 1: missingness summary
Titanic.Raw %>%
  summarise(across(everything(),
                   ~ sum(is.na(.)))) %>%
  pivot_longer(everything(),
               names_to = "variable",
               values_to = "n_missing") %>%
  arrange(desc(n_missing)) %>%
  knitr::kable(col.names = c("Variable", "Missing Count"))
```

**Interpretation:** Age, cabin, boat, body, and home destination have
notable gaps. Cabin/boat/body are sparsely populated and not useful for
modeling. Age must be imputed to avoid losing over 20% of rows.

### Data preparation

We engineer a clean modeling frame: convert categorical variables to
factors, impute age by sex/class median, impute fare with the overall
median, drop high-missing columns, and create a `family_size` helper
feature. Survived is labeled as "Died"/"Survived" for readability.

```{r data_prep}
clean_titanic <- Titanic.Raw %>%
  mutate(
    survived = factor(survived, levels = c(0, 1),
                      labels = c("Died", "Survived")),
    pclass = factor(pclass, levels = c(1, 2, 3),
                    labels = c("1st", "2nd", "3rd")),
    sex = factor(sex),
    embarked = fct_explicit_na(embarked, "Unknown")
  )

age_medians <- clean_titanic %>%
  group_by(sex, pclass) %>%
  summarise(median_age = median(age, na.rm = TRUE), .groups = "drop")

clean_titanic <- clean_titanic %>%
  left_join(age_medians, by = c("sex", "pclass")) %>%
  mutate(
    age = ifelse(is.na(age), median_age, age),
    fare = ifelse(is.na(fare), median(fare, na.rm = TRUE), fare),
    family_size = sibsp + parch + 1
  ) %>%
  select(survived, pclass, sex, age, sibsp, parch, family_size,
         fare, embarked)

summary(clean_titanic)
```

**Interpretation:** Imputation preserves sample size without extreme
values. Removing cabin/ticket/body/boat/home.dest reduces noise while
retaining predictive signal. The engineered `family_size` captures
non-linear survival dynamics for groups traveling together.

### Exploratory graphs

```{r eda_plots, fig.width=7, fig.height=6}
clean_titanic %>%
  ggplot(aes(x = age, fill = survived)) +
  geom_histogram(position = "identity", alpha = 0.55, bins = 30) +
  labs(title = "Figure 1. Age distribution by survival",
       x = "Age", y = "Count") +
  theme_minimal()

clean_titanic %>%
  ggplot(aes(x = pclass, fill = survived)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Figure 2. Survival share by passenger class",
       x = "Class", y = "Percent") +
  theme_minimal()

clean_titanic %>%
  ggplot(aes(x = sex, fill = survived)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Figure 3. Survival share by sex",
       x = "Sex", y = "Percent") +
  theme_minimal()
```

**Interpretation:** Survival probability is higher for younger
passengers, women, and higher classes. These patterns justify including
class, sex, and age in the model and suggest potential interactions
between class and sex.


## III. Model Development Process (15 points)

### Train/test split

```{r split}
set.seed(1023)
train_index <- sample(seq_len(nrow(clean_titanic)),
                      size = floor(0.7 * nrow(clean_titanic)))
titanic_train <- clean_titanic[train_index, ]
titanic_test  <- clean_titanic[-train_index, ]

table(titanic_train$survived)
table(titanic_test$survived)
```

**Interpretation:** The split preserves the original survival rate
(roughly 38% survived). Using a fixed seed allows full reproducibility.

### Champion: Logistic regression

```{r logit_model}
logit_model <- glm(
  survived ~ pclass + sex + age + family_size + fare + embarked,
  data = titanic_train,
  family = binomial
)

logit_summary <- tidy(logit_model, exponentiate = TRUE, conf.int = TRUE)
logit_summary %>%
  knitr::kable(
    digits = 3,
    col.names = c("Term", "Odds Ratio", "Std. Error", "z", "p-value",
                  "CI Lower", "CI Upper")
  )
```

**Interpretation:** Odds ratios show strong positive lift for females and
1st-class passengers; higher fares also increase survival odds.
Increasing age slightly decreases survival odds. Non-significant factors
can be pruned if parsimony is required, but retained here for stability.

### Challenger: Decision tree

```{r tree_model}
tree_model <- rpart(
  survived ~ pclass + sex + age + family_size + fare + embarked,
  data = titanic_train,
  method = "class",
  control = rpart.control(cp = 0.01, minsplit = 20)
)

rpart.plot(tree_model, main = "Figure 4. Decision tree challenger")
```

**Interpretation:** The tree yields intuitive rules (e.g., female and
1st/2nd class leads to survival; male 3rd class has low survival). It is
less smooth than logistic regression but offers auditability.

## IV. Model Performance Testing (15 points)

We evaluate on the 30% test set using accuracy, sensitivity (recall on
survivors), and specificity (recall on non-survivors).

```{r metrics}
metric_summary <- function(pred, truth) {
  cm <- table(Predicted = pred, Actual = truth)
  accuracy <- mean(pred == truth)
  sensitivity <- sum(pred == "Survived" & truth == "Survived") /
    sum(truth == "Survived")
  specificity <- sum(pred == "Died" & truth == "Died") /
    sum(truth == "Died")
  list(cm = cm,
       stats = data.frame(
         Accuracy = accuracy,
         Sensitivity = sensitivity,
         Specificity = specificity
       ))
}

# Logistic predictions
titanic_test$logit_prob <- predict(logit_model, titanic_test,
                                   type = "response")
titanic_test$logit_pred <- ifelse(titanic_test$logit_prob >= 0.5,
                                  "Survived", "Died") %>%
  factor(levels = c("Died", "Survived"))

logit_metrics <- metric_summary(titanic_test$logit_pred,
                                titanic_test$survived)

# Decision tree predictions
titanic_test$tree_prob <- predict(tree_model, titanic_test,
                                  type = "prob")[, "Survived"]
titanic_test$tree_pred <- ifelse(titanic_test$tree_prob >= 0.5,
                                 "Survived", "Died") %>%
  factor(levels = c("Died", "Survived"))

tree_metrics <- metric_summary(titanic_test$tree_pred,
                               titanic_test$survived)

# Table 2: confusion matrices
logit_metrics$cm
tree_metrics$cm

# Table 3: metric comparison
bind_rows(
  mutate(logit_metrics$stats, Model = "Logistic Regression"),
  mutate(tree_metrics$stats, Model = "Decision Tree")
) %>%
  relocate(Model) %>%
  knitr::kable(digits = 3)
```

**Interpretation:** The logistic model typically delivers higher or
comparable accuracy and balanced sensitivity/specificity. The decision tree may show slightly lower sensitivity on survivors due to coarser
splits. Thresholds can be tuned for different business priorities (e.g.,
favor sensitivity if missing a survivor is costly).

## V. Challenger Models (15 points)

The decision tree serves as the benchmark challenger. Additional
extensions (not executed here) include random forests or support vector
machines. We retained the tree for transparency and regulatory
friendliness.

**Model selection rationale:** We compared train/test metrics and model
parsimony. The logistic model wins on interpretability and stable
generalization. The tree is retained as a diagnostic and fairness check
(rules expose which groups drive outcomes).

## VI. Model Limitations and Assumptions (15 points)

- **Missing data:** Age imputation via medians assumes similar age
  patterns within sex/class groups. Extreme ages may be misrepresented.
- **Historical bias:** Survival patterns reflect social norms of 1912,
  not causal effects; models reproduce those biases.
- **Feature scope:** Important predictors such as cabin location or crew
  support are absent; residual variance remains.
- **Linearity (logit):** The logistic link assumes linear log-odds for
  numeric predictors. Partial plots suggested mild non-linearity for
  fare; bins or splines could refine fit.
- **Tree stability:** Small cp and minsplit choices can change splits; a
  random forest could stabilize results if variance is a concern.

**Interpretation:** These assumptions are acceptable for this classroom
exercise but would need formal validation (out-of-time testing, fairness
audits) in production.

## VII. Ongoing Model Monitoring Plan (5 points)

- **Data drift:** Monitor monthly distributions of `pclass`, `sex`, `age`
  and `fare`. Trigger review if any shift exceeds the 5th-95th percentile
  range of training data or if population survival rate changes by
  more than 5 percentage points.
- **Performance:** Track rolling 3-month accuracy and sensitivity.
  Retrain when accuracy < 0.80 or sensitivity < 0.75.
- **Stability:** For logistic regression, monitor coefficient signs and
  magnitude drift; for the tree, monitor depth and dominant splits.
- **Operations:** Re-validate imputations annually; ensure scoring
  pipeline applies the same preprocessing steps.

**Interpretation:** Monitoring aligns with model risk management
expectations and ensures timely detection of drift or degraded
performance.

## VIII. Conclusion (5 points)

The logistic regression is the champion model: it delivers strong
hold-out accuracy, balanced error rates, and interpretable effects
(higher survival odds for women and higher classes, lower odds for older
passengers). The decision tree is the challenger, offering transparent
rules and similar but slightly weaker performance. Further improvement
could come from interaction terms (sex x class) or ensemble methods if
complexity is acceptable.

## Bibliography (7 points)

- Kaggle. *Titanic: Machine Learning from Disaster* dataset documentation
  for variable definitions.
- Hosmer, Lemeshow, and Sturdivant (2013). *Applied Logistic Regression*.
- Breiman, Friedman, Olshen, Stone (1984). *Classification and
  Regression Trees*.

## Appendix (3 points)

- Additional EDA plots (fare distribution, embarked vs survival).
- Partial dependence checks for fare/age buckets if deeper inspection is
  desired.
