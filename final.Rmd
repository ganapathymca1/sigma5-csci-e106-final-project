---
title: "HARVARD EXTENSION SCHOOL"
subtitle: "Titanic Survival Classification: Group Project Report"
author:
- Aljazi Al Maghlouth
- Anjan Chakravarti
- Ganapathy Lakshmanaperumal
- Guy Nguyen-Phuoc
- Jonathan Terrasi
- Julie Lander
- Khatanbaatar Orkhon
- Max Amiesimaka
tags: [logistic regression, decision tree, classification]
abstract: |
  We build a champion/benchmark modeling solution to predict passenger
  survival on the RMS Titanic. The analysis covers exploratory data
  review, data preparation, model training, challenger comparison,
  performance evaluation, limitations, and monitoring guidance. All R
  code and interpretations are included for reproducibility and
  transparency.
date: "`r format(Sys.time(), '%d %B %Y')`"
geometry: margin=1.3cm
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.path = "figures/",
  dev = "png"
)

library(tidyverse)
library(broom)
library(rpart)
library(rpart.plot)
library(MASS)
library(car)
library(caret)
library(pROC)
library(ResourceSelection)
library(vcd)

titanic_raw <- read_csv("Titanic_Survival_Data.csv", show_col_types = FALSE)
```

## Executive Summary

We predict Titanic passenger survival using demographic and ticketing
information. A cleaned dataset of 1,310 records is split 70/30
train/test (set.seed = 1023). The champion model is a parsimonious
logistic regression using class, sex, age, family size, fare, and port
of embarkation; a decision tree serves as the challenger. Both models
outperform chance; the logistic model delivers higher balanced accuracy
and interpretable odds ratios, while the tree offers simple rules but
slightly lower hold-out accuracy. Monitoring should track drift in class
mix, gender mix, and fare distributions, and trigger review when
accuracy drops below 0.80 or when inputs shift beyond training
percentiles. Key limitations include missing values (age, fare, cabin),
historical bias, and simplified imputations.

## I. Introduction (5 points)

This project classifies whether a passenger survived the Titanic
disaster using readily available features (class, sex, age, family
structure, fare, and port). We evaluate two supervised classification
methods: logistic regression (champion) and decision tree (challenger).
Success is defined by accurate and explainable survival predictions that
generalize to the hold-out test set.

## II. Description of the Data and Quality (15 points)

The dataset contains 1,310 observations and 14 original variables. Key
predictors are a mix of categorical (class, sex, embarked) and numeric
(age, fare, family counts). Several variables contain notable missing
values (age, cabin, boat, body, and home destination).

```{r data_overview}
glimpse(titanic_raw)

titanic_raw %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(everything(),
               names_to = "variable",
               values_to = "n_missing") %>%
  arrange(desc(n_missing)) %>%
  knitr::kable(col.names = c("Variable", "Missing Count"))
```

### Data Preparation

We clean and engineer a modeling frame as follows:

1. Convert categorical variables to factors.
2. Impute age by sex/class median.
3. Impute fare with the overall median.
4. Drop high-missing columns.
5. Create a `family_size` helper feature.

```{r data_prep}
clean_titanic <- titanic_raw %>%
  mutate(
    survived = factor(survived, levels = c(0, 1),
                      labels = c("Died", "Survived")),
    pclass = factor(pclass, levels = c(1, 2, 3),
                    labels = c("1st", "2nd", "3rd")),
    sex = factor(sex),
    embarked = fct_explicit_na(embarked, "Unknown")
  )

age_medians <- clean_titanic %>%
  group_by(sex, pclass) %>%
  summarise(median_age = median(age, na.rm = TRUE), .groups = "drop")

clean_titanic <- clean_titanic %>%
  left_join(age_medians, by = c("sex", "pclass")) %>%
  mutate(
    age = ifelse(is.na(age), median_age, age),
    fare = ifelse(is.na(fare), median(fare, na.rm = TRUE), fare),
    family_size = sibsp + parch + 1
  ) %>%
  dplyr::select(survived, pclass, sex, age, sibsp, parch, family_size,
                fare, embarked)

summary(clean_titanic)
```

**Interpretation:** Imputation preserves sample size without extreme
values. Removing cabin/ticket/body/boat/home.dest reduces noise while
retaining predictive signal. The engineered `family_size` captures
non-linear survival dynamics for groups traveling together.

### Exploratory Graphs

```{r eda_plots, fig.width=7, fig.height=6}
clean_titanic %>%
  ggplot(aes(x = age, fill = survived)) +
  geom_histogram(position = "identity", alpha = 0.55, bins = 30) +
  labs(title = "Figure 1. Age distribution by survival",
       x = "Age", y = "Count") +
  theme_minimal()

clean_titanic %>%
  ggplot(aes(x = pclass, fill = survived)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Figure 2. Survival share by passenger class",
       x = "Class", y = "Percent") +
  theme_minimal()

clean_titanic %>%
  ggplot(aes(x = sex, fill = survived)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Figure 3. Survival share by sex",
       x = "Sex", y = "Percent") +
  theme_minimal()
```

**Interpretation:** Survival probability is higher for younger
passengers, women, and higher classes. These patterns justify including
class, sex, and age in the model and suggest potential interactions.

## III. Model Development Process (15 points)

### Train/Test Split

```{r split}
set.seed(1023)
train_index <- sample(seq_len(nrow(clean_titanic)),
                      size = floor(0.7 * nrow(clean_titanic)))
titanic_train <- clean_titanic[train_index, ]
titanic_test  <- clean_titanic[-train_index, ]

table(titanic_train$survived)
table(titanic_test$survived)
```

**Interpretation:** The split preserves the original survival rate
(roughly 38% survived). Using a fixed seed allows reproducibility.

### Champion: Logistic Regression

```{r logit_model}
logit_model <- glm(
  survived ~ pclass + sex + age + family_size + embarked,
  data = titanic_train,
  family = binomial
)

tidy(logit_model, exponentiate = TRUE, conf.int = TRUE) %>%
  knitr::kable(
    digits = 3,
    col.names = c("Term", "Odds Ratio", "Std. Error", "z", "p-value",
                  "CI Lower", "CI Upper")
  )
```

**Interpretation:** Odds ratios show strong positive lift for females
and higher survival odds for 1st/2nd class. Increasing age slightly
decreases survival odds.

### Challenger: Decision Tree

```{r tree_model}
tree_model <- rpart(
  survived ~ pclass + sex + age + family_size + fare + embarked,
  data = titanic_train,
  method = "class",
  control = rpart.control(cp = 0.01, minsplit = 20)
)

rpart.plot(tree_model, main = "Figure 4. Decision tree challenger")
```

**Interpretation:** The tree yields intuitive rules (e.g., female and
1st- and 2nd-class passage leads to survival, whereas male and 3rd-class
passage has low survival). It trades probability granularity for
transparency.

## IV. Model Performance Testing (15 points)

### 4.1 Model Selection and Diagnostics

```{r stepwise_selection}
# Full logistic model
logit_full <- glm(
  survived ~ pclass + sex + age + family_size + fare + embarked,
  data = titanic_train,
  family = binomial
)

# Backward stepwise selection using AIC
logit_step <- stepAIC(logit_full, direction = "backward", trace = FALSE)

# Compare AIC values
cat("Full model AIC:", AIC(logit_full), "\n")
cat("Stepwise model AIC:", AIC(logit_step), "\n")
```

#### Multicollinearity (VIF)

```{r vif_check}
vif_values <- vif(logit_step)

vif_df <- if (is.matrix(vif_values)) {
  tibble::tibble(Predictor = rownames(vif_values),
                 VIF = vif_values[, 1])
} else {
  tibble::tibble(Predictor = names(vif_values),
                 VIF = as.numeric(vif_values))
}

vif_df %>%
  knitr::kable(digits = 2, caption = "Table 1: Variance Inflation Factors")
```

#### Linearity of the Logit (Box-Tidwell)

```{r box_tidwell}
titanic_train_bt <- titanic_train %>%
  mutate(
    age_log = age * log(age + 1),
    fare_log = fare * log(fare + 1),
    family_size_log = family_size * log(family_size + 1)
  )

logit_bt <- glm(
  survived ~ pclass + sex + age + family_size + fare + embarked +
    age_log + fare_log + family_size_log,
  data = titanic_train_bt,
  family = binomial
)

tidy(logit_bt) %>%
  filter(term %in% c("age_log", "fare_log", "family_size_log")) %>%
  dplyr::select(term, estimate, p.value) %>%
  knitr::kable(digits = 4,
               caption = "Table 2: Box-Tidwell Linearity Test")
```

#### Influential Observations (Cook's Distance)

```{r  cooks_distance, fig.width=7, fig.height=4, fig.align='left'}
cooksd <- cooks.distance(logit_step)

plot(cooksd, pch = 20,
     main = "Figure 5. Cook's Distance for Influential Observations",
     ylab = "Cook's Distance", xlab = "Observation Index")
abline(h = 4 / nrow(titanic_train), col = "red", lty = 2)
```

### 4.2 Test Set Performance

```{r test_predictions}
# Logistic regression predictions
logit_pred_prob <- predict(logit_step, newdata = titanic_test, type = "response")
logit_pred_class <- ifelse(logit_pred_prob > 0.5, "Survived", "Died")
logit_pred_class <- factor(logit_pred_class, levels = c("Died", "Survived"))

# Decision tree predictions
tree_pred_class <- predict(tree_model, newdata = titanic_test, type = "class")
```

#### Confusion Matrices

```{r confusion_matrices}
logit_cm <- confusionMatrix(logit_pred_class, titanic_test$survived, positive = "Survived")
tree_cm  <- confusionMatrix(tree_pred_class, titanic_test$survived,  positive = "Survived")

logit_cm$table
logit_cm$overall
logit_cm$byClass

tree_cm$table
tree_cm$overall
tree_cm$byClass
```

#### Performance Metrics Comparison

```{r metrics_comparison}
metrics_comparison <- data.frame(
  Model = c("Logistic Regression", "Decision Tree"),
  Accuracy = c(logit_cm$overall["Accuracy"], tree_cm$overall["Accuracy"]),
  Sensitivity = c(logit_cm$byClass["Sensitivity"], tree_cm$byClass["Sensitivity"]),
  Specificity = c(logit_cm$byClass["Specificity"], tree_cm$byClass["Specificity"]),
  Precision = c(logit_cm$byClass["Precision"], tree_cm$byClass["Precision"]),
  F1_Score = c(logit_cm$byClass["F1"], tree_cm$byClass["F1"]),
  Balanced_Accuracy = c(logit_cm$byClass["Balanced Accuracy"],
                        tree_cm$byClass["Balanced Accuracy"])
)

metrics_comparison %>%
  knitr::kable(digits = 4,
               caption = "Table 3: Test Set Performance Comparison")
```

#### ROC Curve and AUC

```{r roc_auc, fig.width=7, fig.height=6}
logit_roc <- roc(titanic_test$survived, logit_pred_prob, levels = c("Died", "Survived"))
logit_auc <- auc(logit_roc)

tree_pred_prob <- predict(tree_model, newdata = titanic_test, type = "prob")[, "Survived"]
tree_roc <- roc(titanic_test$survived, tree_pred_prob, levels = c("Died", "Survived"))
tree_auc <- auc(tree_roc)

plot(logit_roc, col = "blue", lwd = 2,
     main = "Figure 6. ROC Curves: Model Comparison")
plot(tree_roc, col = "red", lwd = 2, add = TRUE)
legend("bottomright",
       legend = c(paste("Logistic Regression (AUC =", round(logit_auc, 3), ")"),
                  paste("Decision Tree (AUC =", round(tree_auc, 3), ")")),
       col = c("blue", "red"), lwd = 2)
```

#### Goodness-of-Fit

```{r goodness_of_fit}
# Pseudo R-squared (McFadden)
logit_null <- glm(survived ~ 1, data = titanic_train, family = binomial)
pseudo_r2 <- 1 - (as.numeric(logLik(logit_step)) / as.numeric(logLik(logit_null)))

# Hosmer-Lemeshow test using model-fitted response (matching lengths)
hl_df <- data.frame(
  y = as.numeric(logit_step$y),
  yhat = as.numeric(fitted(logit_step))
)
hl_df <- na.omit(hl_df)

hl_test <- hoslem.test(hl_df$y, hl_df$yhat, g = 10)

cat("McFadden's Pseudo R^2:", round(pseudo_r2, 4), "\n")
cat("Hosmer-Lemeshow p-value:", round(hl_test$p.value, 4), "\n")
```

#### Residual Analysis

```{r residual_plot, fig.width=7, fig.height=5}
residuals_dev <- residuals(logit_step, type = "deviance")

plot(fitted(logit_step), residuals_dev,
     pch = 20, col = scales::alpha("black", 0.5),
     xlab = "Fitted Values (Log-Odds)", ylab = "Deviance Residuals",
     main = "Figure 7. Deviance Residuals vs. Fitted Values")
abline(h = 0, col = "red", lty = 2)
```

### 4.3 Champion Model Summary

```{r champion_summary}
cat("=== CHAMPION MODEL SUMMARY ===\n\n")
cat("Model Type: Logistic Regression (Stepwise Selected)\n")
cat("Test Accuracy:", round(logit_cm$overall["Accuracy"], 4), "\n")
cat("Test AUC:", round(logit_auc, 4), "\n")
cat("Pseudo R^2:", round(pseudo_r2, 4), "\n")
cat("Multicollinearity: VIF values <", round(max(vif_values), 2), "\n")
cat("Linearity of Logit: Assessed via Box-Tidwell\n")
cat("Goodness-of-Fit: Hosmer-Lemeshow p-value =", round(hl_test$p.value, 4), "\n\n")

tidy(logit_step, exponentiate = TRUE, conf.int = TRUE) %>%
  knitr::kable(digits = 3,
               col.names = c("Term", "Odds Ratio", "Std. Error",
                             "z", "p-value", "CI Lower", "CI Upper"))
```

## V. Challenger Models (15 points)

- Decision tree (rpart) built with the same predictors.
- Provides transparent decision rules but slightly lower AUC/accuracy.
- Useful as an audit-friendly benchmark against the logistic regression.

## VI. Model Limitations and Assumptions (15 points)

- Missing data handled with median imputations; alternative methods
  (e.g., multiple imputation) could shift coefficients.  
- Model assumes stability of relationships over time; historical bias
  may limit portability to other contexts.  
- Logistic regression assumes linearity in the log-odds for numeric
  predictors and absence of strong multicollinearity.  
- Outliers may influence coefficients despite Cook's distance checks.

## VII. Ongoing Model Monitoring Plan (5 points)

- **Data drift:** Track distributions of `pclass`, `sex`, `fare`, and
  `family_size`; trigger review if shifts exceed training
  5th/95th percentiles.  
- **Performance:** Recompute accuracy, balanced accuracy, and AUC
  quarterly; retrain if accuracy < 0.80 or AUC < 0.78.  
- **Stability:** Monitor calibration (Hosmer-Lemeshow) and confusion
  matrix balance; investigate rising false negatives (missed survivors).  
- **Process:** Freeze scoring code, log model version/seed, and maintain
  challenger comparisons on new data.

## VIII. Conclusion (5 points)

The stepwise logistic regression is the champion model: it delivers
strong discriminatory power, balanced performance, and interpretable
odds ratios. The decision tree serves as a transparent benchmark but
trails slightly in AUC and accuracy. Monitoring should focus on input
drift and sustained predictive performance to ensure continued fitness
for purpose.

## Bibliography (7 points)

- "Titanic: Machine Learning from Disaster," Kaggle.
- James, Witten, Hastie, Tibshirani. *An Introduction to Statistical
  Learning* (Ch. 4â€“6).
- Kuhn, Johnson. *Applied Predictive Modeling*.

## Appendix (3 points)

- Additional exploratory plots (boxplots, mosaic plots, and correlation
  checks) are available in the EDA code chunks above. Adjust binning and
  facetting as needed for presentation.
